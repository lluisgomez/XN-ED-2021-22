{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:dl-minicourse] *",
      "language": "python",
      "name": "conda-env-dl-minicourse-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "XN-ED Lab00-Intro_Tensors.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "o-_70bB17jb4",
        "R8N-hhzmQZaA"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkaratzas/XNAP_Profs/blob/main/W01_01_Intro_Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Intro | Neural Networks and Deep Learning\n",
        "\n",
        "In this notebook we introduce some basic tools and concepts that will be used throught the practical sessions of the course. \n",
        "\n",
        "Credit: some parts of this notebook have been taken from the [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)."
      ],
      "metadata": {
        "id": "x8vLnziRk4XK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions and basic set-up\n",
        "\n",
        "The course's lab material will be made available in the virtual campus (section \"Materials\") as well as through the GitHub repository of the course which is at: https://github.com/lluisgomez/XN-ED-2021-22\n",
        "\n",
        "To work from home it is recommended to use [Google CoLab](https://colab.research.google.com/). Alternatively, you can use [Amazon SageMaker Studio Lab](https://studiolab.sagemaker.aws/).\n",
        "\n",
        "If you decide to use either Google CoLab or Amazon SageMaker Studio, remember that you can open notebooks directly from the GitHub repository of the course.\n",
        "\n",
        "To work offline, you can install any Python distribution (e.g. [Anaconda 3](https://www.anaconda.com/products/individual)) and [Jupyter](https://jupyter.org/). You will also need to install necessary modules, principally: Numpy, Matplotlib, Pytorch. If you decide to work offline, you should download the notebook files from this page or from the course's GitHub to your computer."
      ],
      "metadata": {
        "id": "ktDLzJSMprW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jupyter and Colab\n",
        "\n",
        "Jupyter Notebook is a web based application for creating and sharing computational documents. It offers a simple, streamlined, document-centric experience.\n",
        "\n",
        "The Jupyter Notebook has become a popular user interface for cloud computing, and many cloud providers have adopted the Jupyter Notebook or derivative tools as a frontend interface for cloud users. Examples include Amazon's SageMaker Notebooks, and Google's Colaboratory.\n",
        "\n",
        "[Google Colaboratory](https://colab.research.google.com/) (also known as Colab) is a free Jupyter notebook environment that runs in the cloud. Colab allows you to write and execute Python in your browser, with \n",
        "- Zero configuration required\n",
        "- Free access to GPUs\n",
        "- Easy sharing\n",
        "\n",
        "If you have never used Colab we recommend you to take a look to the [Welcome to Colab Notebook](https://colab.research.google.com/notebooks/intro.ipynb)."
      ],
      "metadata": {
        "id": "9j0G_475ra2m"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IF4i31_7jbg"
      },
      "source": [
        "\n",
        "## What is PyTorch?\n",
        "\n",
        "[PyTorch](https://pytorch.org/) is a Python based scientific computing package targeted at two sets of audiences:\n",
        "\n",
        "-  Tensor library with GPU acceleration\n",
        "-  A deep learning research platform that provides maximum flexibility and speed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ng2mpMYgkpu"
      },
      "source": [
        "### Import the library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzX92S587jbm"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y62dQH467jbn"
      },
      "source": [
        "### Getting quick help and autompletions in Jupyter/Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab provides automatic completions to explore attributes of Python objects, as well as to quickly view documentation strings. As an example, insert your cursor after `torch` and press **Period**(`.`), you will see the list of available completions within the `torch` module. Completions can be opened again by using **Ctrl+Space**."
      ],
      "metadata": {
        "id": "MS0LF_C7vVeR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g-D23eg7jbn"
      },
      "source": [
        "torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you type an open parenthesis after any function or class in the module, you will see a pop-up of its documentation string:"
      ],
      "metadata": {
        "id": "Dyf6n2gVygFC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED3Z0RKO7jbo"
      },
      "source": [
        "torch.nn.Linear"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To quickly access documentation, type ? before or after an object and press the run key (**Shift+Enter**)."
      ],
      "metadata": {
        "id": "HWEkGyHRw0x2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.Tensor?"
      ],
      "metadata": {
        "id": "xfo_6eh_xUd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jupyter also provides a means of wildcard matching for names using the `*` character."
      ],
      "metadata": {
        "id": "9M8TZHWoyAwL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIqY0-QT7jbo"
      },
      "source": [
        "# What about all `*Tensor`s?\n",
        "torch.*Tensor?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To quickly access documentation including the source code, type ?? before or after an object and press the run key (**Shift+Enter**)"
      ],
      "metadata": {
        "id": "vTYBrKe6zUWs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6gVzBNi7jbp"
      },
      "source": [
        "torch.nn.Module??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3odUxKDa7jbq"
      },
      "source": [
        "### First steps with Torch Tensors\n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays and matrices. In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model‚Äôs parameters.\n",
        "\n",
        "Tensors are similar to [NumPy‚Äôs](https://numpy.org/) ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see [Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label) for more details). Tensors are also optimized for automatic differentiation. We‚Äôll see a bit more about automatic differentiation later in the Gradient Computation section, but you will get a much better understanding of it in the next lab session (next week Autograd Notebook). If you‚Äôre familiar with ndarrays, you‚Äôll be right at home with the Tensor API. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initializing Tensors\n",
        "\n",
        "Tensors can be initialized in various ways. Take a look at the following examples:\n",
        "\n",
        "**Directly from data**\n",
        "\n",
        "Tensors can be created directly from data. The data type is automatically inferred."
      ],
      "metadata": {
        "id": "LxmnKm9G5svJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "\n",
        "print(x_data)\n",
        "print(type(x_data))"
      ],
      "metadata": {
        "id": "GGlN62NW5wGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From a NumPy array**\n",
        "\n",
        "Tensors can be created from NumPy arrays (and vice versa)."
      ],
      "metadata": {
        "id": "loNTnct058Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "0NeW5zVj6I7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From another tensor:**\n",
        "\n",
        "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden."
      ],
      "metadata": {
        "id": "pi2nEe1E6Q-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "id": "0vkpEcHM6Wl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With random or constant values:**\n",
        "\n",
        "``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor."
      ],
      "metadata": {
        "id": "To8rGBD76qjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "id": "RKj_FFRe6wAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attributes of a Tensor\n",
        "\n",
        "Tensor attributes describe their shape, datatype, and the device on which they are stored."
      ],
      "metadata": {
        "id": "qhmIBWUd7He-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3,4)\n",
        "print(tensor)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "id": "rpQjHEsM7QXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Tensor class has also many useful methods for getting / inspecting Tensors attributes."
      ],
      "metadata": {
        "id": "Q4NZDEIs8Et5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXAmpH-Z7jbr"
      },
      "source": [
        "print(f'Tensor size: {tensor.size()}')\n",
        "print(f'Numnber of elements: {tensor.numel()}')\n",
        "print(f'Dimensions: {tensor.dim()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Operations on Tensors\n",
        "\n",
        "Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing,\n",
        "indexing, slicing), sampling and more are\n",
        "comprehensively described [here](https://pytorch.org/docs/stable/torch.html).\n",
        "\n",
        "Try out some of the operations from the list.\n",
        "If you're familiar with the NumPy API, you'll find the Tensor API a breeze to use.\n",
        "\n",
        "**Standard numpy-like indexing and slicing:**"
      ],
      "metadata": {
        "id": "088yebcs9FdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "print(f\"Last column: {tensor[..., -1]}\")\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "S69ictWp_Gg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Joining tensors** \n",
        "\n",
        "You can use ``torch.cat`` to concatenate a sequence of tensors along a given dimension.\n",
        "See also [`torch.stack`](https://pytorch.org/docs/stable/generated/torch.stack.html>),\n",
        "another tensor joining op that is subtly different from ``torch.cat``."
      ],
      "metadata": {
        "id": "QfPzOrys_Xyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "id": "n5uJGK-h_nGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Arithmetic Operations**"
      ],
      "metadata": {
        "id": "qNFz171Y_uaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(tensor)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)"
      ],
      "metadata": {
        "id": "vKIHLlR7_0V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In-place operations**\n",
        "\n",
        "Operations that store the result into the operand are called in-place. They are denoted by a ``_`` suffix.\n",
        "For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``."
      ],
      "metadata": {
        "id": "gtRQLuHiAJpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "084fsIURAGdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss\n",
        "     of history. Hence, their use is discouraged.</p></div>"
      ],
      "metadata": {
        "id": "xIyRbzY1ATyd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr_McMDdAc3L"
      },
      "source": [
        "# Mind the underscore!\n",
        "# Any operation that mutates a tensor in-place is post-fixed with an _.\n",
        "# For example: x.copy_(y), x.t_(), x.random_(n) will change x.\n",
        "tensor.random_(10)\n",
        "print(tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIVYl69jAc3P"
      },
      "source": [
        "# As you can see zero_ would replace r with 0's which was originally filled with integers\n",
        "tensor.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yGGuawb7jb3"
      },
      "source": [
        "#### Using the GPU\n",
        "\n",
        "Each of these operations can be run on the GPU (at typically higher speeds than on a CPU). If you‚Äôre using Colab, allocate a GPU by going to Runtime > Change runtime type > GPU.\n",
        "\n",
        "By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using ``.to`` method (after checking for GPU availability). Keep in mind that copying large tensors across devices can be expensive in terms of time and memory!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3cSABmzDda2"
      },
      "source": [
        "# If this cell fails you need to change the runtime of your colab notebook to GPU\n",
        "# Go to Runtime -> Change Runtime Type and select GPU\n",
        "assert torch.cuda.is_available(), \"GPU is not enabled\"\n",
        "\n",
        "# use the first gpu available if possible\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rQvVYDMFIAW"
      },
      "source": [
        "# Tensors can be moved between gpu and cpu memory\n",
        "\n",
        "tensor = torch.randn(5, 5) # create a 5x5 matrix filled with random numbers\n",
        "print(f\"tensor's device: {tensor.device}\") # by default tensors are stored in cpu memory (RAM)\n",
        "\n",
        "# Move your tensor to GPU device 0 if there is one (first GPU in the system)\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(device) # tensor.cuda() is an alternative although not recommended\n",
        "print(f\"tensor's device: {tensor.device}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccZpZ5xzZ8Sy"
      },
      "source": [
        "# A common mistake \n",
        "a = torch.randn(5, 2, device=device)\n",
        "b = torch.randn(1, 2)\n",
        "\n",
        "# This throws an exception, since you can't operate on tensors stored in\n",
        "# different devices, and the error message is pretty clear about that\n",
        "c = a * b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir1URH3v7jbt"
      },
      "source": [
        "### Playing with Vectors (1D Tensors)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRCvA1R17jbt"
      },
      "source": [
        "# Creates a 1D tensor of integers 1 to 4\n",
        "v = torch.Tensor([1, 2, 3, 4])\n",
        "v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmkSLrIi7jbt"
      },
      "source": [
        "# Print number of dimensions (1D) and size of tensor\n",
        "print(f'dim: {v.dim()}, size: {v.size()[0]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K03oi68R7jbu"
      },
      "source": [
        "w = torch.Tensor([1, 0, 2, 0])\n",
        "w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGGpVC_b7jbu"
      },
      "source": [
        "# Element-wise multiplication\n",
        "v * w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq7-Aqs_7jbu"
      },
      "source": [
        "# Scalar product: 1*1 + 2*0 + 3*2 + 4*0\n",
        "v @ w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-oXbFTO7jbu"
      },
      "source": [
        "# In-place replacement of random number from 0 to 10\n",
        "x = torch.Tensor(5).random_(10)\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00BUa-L47jbu"
      },
      "source": [
        "print(f'first: {x[0]}, last: {x[-1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX_Uy_T17jbu"
      },
      "source": [
        "# Extract sub-Tensor [from:to)\n",
        "x[1:2 + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPNJt5Kt7jbv"
      },
      "source": [
        "# Create a tensor with integers ranging from 1 to 5, excluding 5\n",
        "v = torch.arange(1, 4 + 1)\n",
        "v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_nwZPg-7jbv"
      },
      "source": [
        "# Square all elements in the tensor\n",
        "print(v.pow(2), v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De7wobZv7jbv"
      },
      "source": [
        "### Playing with Matrices (2D Tensors)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuiyP0MK7jbv"
      },
      "source": [
        "# Create a 2x4 tensor\n",
        "m = torch.Tensor([[2, 5, 3, 7],\n",
        "                  [4, 2, 1, 9]])\n",
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI36U8sv7jbv"
      },
      "source": [
        "m.dim()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f91z4dw7jbw"
      },
      "source": [
        "print(m.size(0), m.size(1), m.size(), sep=' -- ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vuLnT2z7jbw"
      },
      "source": [
        "# Indexing row 0, column 2 (0-indexed)\n",
        "m[0][2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLIC7pG97jbw"
      },
      "source": [
        "# Indexing row 0, column 2 (0-indexed)\n",
        "m[0, 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsutF_zc7jbw"
      },
      "source": [
        "# Indexing column 1, all rows (returns size 2)\n",
        "m[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLg24cHx7jbw"
      },
      "source": [
        "# Indexing column 1, all rows (returns size 2x2)\n",
        "m[:, [1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8nu79EU7jbx"
      },
      "source": [
        "# Indexes row 0, all columns (returns 1x4)\n",
        "m[[0], :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYVpTC7l7jbx"
      },
      "source": [
        "# Create tensor of numbers from 1 to 5 (excluding 5)\n",
        "v = torch.arange(1., 4 + 1)\n",
        "v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UQd3S3w7jbx"
      },
      "source": [
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c10o4XUQ7jbx"
      },
      "source": [
        "# Scalar product\n",
        "m @ v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEkCtsZG7jbx"
      },
      "source": [
        "# Calculated by 1*2 + 2*5 + 3*3 + 4*7\n",
        "m[0, :] @ v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzxKEjus7jby"
      },
      "source": [
        "# Calculated by \n",
        "m[[1], :] @ v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP7c5qI17jby"
      },
      "source": [
        "# Add a random tensor of size 2x4 to m\n",
        "m + torch.rand(2, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nli9YIb17jby"
      },
      "source": [
        "# Subtract a random tensor of size 2x4 to m\n",
        "m - torch.rand(2, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0QPbbr87jby"
      },
      "source": [
        "# Multiply a random tensor of size 2x4 to m\n",
        "m * torch.rand(2, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRxwhq3p7jby"
      },
      "source": [
        "# Divide m by a random tensor of size 2x4\n",
        "m / torch.rand(2, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFjUamkg7jby"
      },
      "source": [
        "m.size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88uWT_-N7jbz"
      },
      "source": [
        "# Transpose tensor m, which is essentially 2x4 to 4x2\n",
        "m.t()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfx8uRtl7jbz"
      },
      "source": [
        "# Same as\n",
        "m.transpose(0, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix product of two tensors.\n",
        "\n",
        "tensor1 = torch.randn(3)\n",
        "tensor2 = torch.randn(3)\n",
        "torch.matmul(tensor1, tensor2)"
      ],
      "metadata": {
        "id": "XANSA5LpE-ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 3)\n",
        "torch.mm(mat1, mat2)"
      ],
      "metadata": {
        "id": "pcVwnfCUFG7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p2bHHeHJewn"
      },
      "source": [
        "### Broadcasting\n",
        "\n",
        "Many PyTorch operations support NumPy‚Äôs broadcasting semantics. See https://numpy.org/doc/stable/user/basics.broadcasting.html for details.\n",
        "\n",
        "In short, if a PyTorch operation supports broadcast, then its Tensor arguments can be automatically expanded to be of equal sizes (without making copies of the data).\n",
        "\n",
        "Two tensors are ‚Äúbroadcastable‚Äù if the following rules hold:\n",
        "\n",
        "*   Each tensor has at least one dimension.\n",
        "*   When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPyg44mxJeHP"
      },
      "source": [
        "x=torch.empty(5,7,3)\n",
        "y=torch.empty(5,7,3)\n",
        "# x and y are broadcastable since all dimensions are equal\n",
        "\n",
        "x=torch.empty((0,))\n",
        "y=torch.empty(2,2)\n",
        "# x and y are not broadcastable, because x does not have at least 1 dimension\n",
        "\n",
        "x=torch.empty(5,3,4,1)\n",
        "y=torch.empty(  3,1,1)\n",
        "# x and y are broadcastable.\n",
        "# 1st trailing dimension: both have size 1\n",
        "# 2nd trailing dimension: y has size 1\n",
        "# 3rd trailing dimension: x size == y size\n",
        "# 4th trailing dimension: y dimension doesn't exist\n",
        "\n",
        "# but:\n",
        "x=torch.empty(5,2,4,1)\n",
        "y=torch.empty(  3,1,1)\n",
        "# x and y are not broadcastable, because in the 3rd trailing dimension 2 != 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpudbDP9MI4U"
      },
      "source": [
        "# How is the output dimension calculated?\n",
        "x=torch.empty(5,1,4,1)\n",
        "y=torch.empty(3,1,1)\n",
        "print((x+y).size())\n",
        "\n",
        "x=torch.empty(1)\n",
        "y=torch.empty(3,1,7)\n",
        "print((x+y).size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpCZhT8U7jbz"
      },
      "source": [
        "### Other Constructors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYn7XeYu7jbz"
      },
      "source": [
        "# Create tensor from 3 to 8, with each having a space of 1\n",
        "torch.arange(3., 8 + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH8X7Dts7jbz"
      },
      "source": [
        "# Create tensor from 5.7 to -2.1 with each having a space of -3\n",
        "torch.arange(5.7, -2.1, -3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B14Dyrn7jbz"
      },
      "source": [
        "# returns a 1D tensor of steps equally spaced points between start=3, end=8 and steps=20\n",
        "torch.linspace(3, 8, 20).view(1, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb4KEmjU7jb0"
      },
      "source": [
        "# Create a tensor filled with 0's\n",
        "torch.zeros(3, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrOxrng27jb0"
      },
      "source": [
        "# Create a tensor filled with 1's\n",
        "torch.ones(3, 2, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt6VUo1A7jb0"
      },
      "source": [
        "# Create a tensor with the diagonal filled with 1\n",
        "torch.eye(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDCnuhOf7jb0"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81dgFtq67jb0"
      },
      "source": [
        "# Numpy bridge!\n",
        "plt.hist(torch.randn(1000).numpy(), 100);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBhx09297jb1"
      },
      "source": [
        "plt.hist(torch.randn(10**6).numpy(), 100);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyeN3wTV7jb1"
      },
      "source": [
        "### Casting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxMGbcNP7jb1"
      },
      "source": [
        "# Helper to get what kind of tensor types\n",
        "torch.*Tensor?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6pXTH4b7jb1"
      },
      "source": [
        "m = torch.Tensor([[2, 5, 3, 7],\n",
        "                  [4, 2, 1, 9]])\n",
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TAG0hTN7jb2"
      },
      "source": [
        "# This is basically a 64 bit float tensor\n",
        "m_double = m.double()\n",
        "m_double"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFe9nMZi7jb2"
      },
      "source": [
        "# This creates a tensor of type int8\n",
        "m_byte = m.byte()\n",
        "m_byte"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSVzhX_I7jb2"
      },
      "source": [
        "# Converts tensor to numpy array\n",
        "m_np = m.numpy()\n",
        "m_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHfSv9BB7jb2"
      },
      "source": [
        "# In-place fill of column 0 and row 0 with value -1\n",
        "m_np[0, 0] = -1\n",
        "m_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICAeMZLU7jb3"
      },
      "source": [
        "m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CStd3ORV7jb3"
      },
      "source": [
        "# Create a tensor of integers ranging from 0 to 4\n",
        "import numpy as np\n",
        "n_np = np.arange(5)\n",
        "n = torch.from_numpy(n_np)\n",
        "print(n_np, n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gGi0E-h7jb3"
      },
      "source": [
        "# In-place multiplication of all elements by 2 for tensor n\n",
        "n.mul_(2)\n",
        "n_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Views and Strides\n",
        "\n",
        "The `Tensor.view(*shape)` method returns a new tensor with the same data as the self tensor but of a different shape.\n",
        "\n",
        "The returned tensor shares the same data and must have the same number of elements, but may have a different size. For a tensor to be viewed, the new view size must be compatible with its original size and stride."
      ],
      "metadata": {
        "id": "DIYApWNwBTiY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ARC3wOQ7jbr"
      },
      "source": [
        "t = torch.zeros(3, 4, 2)\n",
        "t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL2ajaMg7jbs"
      },
      "source": [
        "r = t.view(3, 8)\n",
        "r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIhTq4nIdqx7"
      },
      "source": [
        "# What are the Tensor strides and how are they related to shapes?\n",
        "print(t.stride(), r.stride())\n",
        "print(t.shape, r.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x59Bo0QnEUOU"
      },
      "source": [
        "## Gradient Computation\n",
        "\n",
        "You will get a much better understanding of gradient computations and automatic differentiation in the next lab session (next week Autograd Notebook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H25IsxuRKlry"
      },
      "source": [
        "# Tensors also track the operations applied on them in order to differentiate them\n",
        "\n",
        "# setting requires_grad to true tells the autograd engine that we want to compute\n",
        "# gradients for this tensor\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "\n",
        "L = 3*a**3\n",
        "L.sum().backward()\n",
        "print(f\"Gradient of a with respecto to L: {a.grad}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnviODjmRdKC"
      },
      "source": [
        "Lets check if the computed gradients are correct:\n",
        "\n",
        "$\n",
        "\\frac{\\partial{L}}{\\partial{a}} = [9 * a_1^2, 9 * a_2^2] \\\\\n",
        "\\frac{\\partial{L}}{\\partial{a}} = [9 * 2^2, 9 * 3^2] \\\\\n",
        "\\frac{\\partial{L}}{\\partial{a}} = [36, 81]\n",
        "$\n",
        "\n",
        "As we can see the gradient vector matches the one computed by the autograd engine (no surprise there)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61qpDwtvU_E8"
      },
      "source": [
        "# Notice that the output tensor of an operation will require gradients even \n",
        "# if only a single input tensor has requires_grad=True.\n",
        "\n",
        "x = torch.rand(5, 5)\n",
        "y = torch.rand(5, 5)\n",
        "z = torch.rand((5, 5), requires_grad=True)\n",
        "\n",
        "a = x + y\n",
        "print(f\"Does a require gradients? : {a.requires_grad}\")\n",
        "b = x + z\n",
        "print(f\"Does b require gradients?: {b.requires_grad}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-_70bB17jb4"
      },
      "source": [
        "## Much more\n",
        "\n",
        "There's definitely much more, but this was the basics about `Tensor`s.\n",
        "\n",
        "We strongly recommend you to take a look at the *Torch* API Documentation [here](https://pytorch.org/docs/stable/index.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xl6U-RoEtY3"
      },
      "source": [
        "# Homework\n",
        "\n",
        "A) The code below simulates a tiny neural network, however it throws an exception. As you build neural networks in PyTorch you will see this exception **often**. Look at the error message, explain whats happening and make the necessary changes to the code to get an output from this tiny network\n",
        "\n",
        "B) Once you manage to sucessfully run the code below notice how the shape of the tensors ```fts``` and ```bias``` are drastically different, yet they can be added together. Which internal PyTorch mechanism makes this addition happen?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aGsG2MMGebg"
      },
      "source": [
        "### Generate some data\n",
        "torch.manual_seed(7) # Set the random seed so things are predictable\n",
        "\n",
        "# Features are 5 random normal variables\n",
        "features = torch.randn((1, 5))\n",
        "# True weights for our data, random normal variables again\n",
        "weights = torch.randn_like(features)\n",
        "# and a true bias term\n",
        "bias = torch.randn((1, 1))\n",
        "fts = torch.mm(features, weights)\n",
        "print(fts + bias)\n",
        "print(fts.shape, bias.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8N-hhzmQZaA"
      },
      "source": [
        "C) Answer the following questions about the cell below\n",
        "\n",
        "1. Does the value of ```t``` change? Why?\n",
        "2. Does the shape of ```t``` change? Why?\n",
        "3. Explain, in your own words. What is the stride of a tensor, why is it convenient to have them?\n",
        "4.  Pick a mathematical operation like cosine or square root (not those though üôÇ). Can you find elementwise operations in the [torch library](https://pytorch.org/docs/stable/torch.html#pointwise-ops). \n",
        "5. Apply the function element-wise to ```a```. Does it return an error? Why? How can it be fixed?\n",
        "6. Is there a version of the function that operates in place?\n",
        "7. Run the same funcion on the GPU. Do you notice any difference in runtime? If not, why do you think that is?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__SC70eiXYn1"
      },
      "source": [
        "t = torch.tensor(list(range(9)))\n",
        "\n",
        "a = t.view(3, 3)\n",
        "a.mul_(2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}